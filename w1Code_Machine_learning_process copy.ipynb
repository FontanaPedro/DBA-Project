{"cells":[{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Import Libraries"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LinearRegression, Ridge, Lasso\n","from sklearn.tree import DecisionTreeRegressor\n","from sklearn.ensemble import RandomForestRegressor,RandomForestClassifier, GradientBoostingRegressor\n","from sklearn.neural_network import MLPClassifier, MLPRegressor\n","from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n","from sklearn.preprocessing import MinMaxScaler,StandardScaler\n","from sklearn import tree\n","\n","\n","\n","\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Read file"]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Shape:  (57007, 21)\n"]},{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>yearMonth_sale</th>\n","      <th>case_type_dk</th>\n","      <th>zip_code_name</th>\n","      <th>erts89_utm32_x</th>\n","      <th>erts89_utm32_y</th>\n","      <th>ed50_x</th>\n","      <th>ed50_y</th>\n","      <th>wgs84_lat</th>\n","      <th>wgs84_lon</th>\n","      <th>residental_area</th>\n","      <th>measured_area</th>\n","      <th>energy_labeled_required</th>\n","      <th>energy_labeled</th>\n","      <th>amount_of_toilets</th>\n","      <th>year_of_construction</th>\n","      <th>renovation_year</th>\n","      <th>first_offer_price</th>\n","      <th>lastest_announced_price</th>\n","      <th>sold_price</th>\n","      <th>days_on_the_market_all_broker</th>\n","      <th>change_broker</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>201805</td>\n","      <td>Rækkehus</td>\n","      <td>København Ø</td>\n","      <td>724656.3099617342</td>\n","      <td>6177510.129902037</td>\n","      <td>724738.3771995398</td>\n","      <td>6177716.274317907</td>\n","      <td>55,69125957</td>\n","      <td>12,57452761</td>\n","      <td>121</td>\n","      <td>136.0</td>\n","      <td>True</td>\n","      <td>c</td>\n","      <td>2</td>\n","      <td>1882</td>\n","      <td>0</td>\n","      <td>9895000</td>\n","      <td>9500000</td>\n","      <td>8500000</td>\n","      <td>79</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>201805</td>\n","      <td>Rækkehus</td>\n","      <td>København Ø</td>\n","      <td>724612.6998841494</td>\n","      <td>6177539.480294425</td>\n","      <td>724694.7669242901</td>\n","      <td>6177745.625006782</td>\n","      <td>55,69154296</td>\n","      <td>12,57385928</td>\n","      <td>136</td>\n","      <td>151.0</td>\n","      <td>True</td>\n","      <td>c</td>\n","      <td>2</td>\n","      <td>1882</td>\n","      <td>1</td>\n","      <td>9595000</td>\n","      <td>9195000</td>\n","      <td>8750000</td>\n","      <td>96</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>202006</td>\n","      <td>Villa</td>\n","      <td>København S</td>\n","      <td>726339.2701369224</td>\n","      <td>6172005.4193364065</td>\n","      <td>726421.3337691108</td>\n","      <td>6172211.5248479135</td>\n","      <td>55,64111328</td>\n","      <td>12,59671021</td>\n","      <td>107</td>\n","      <td>126.0</td>\n","      <td>True</td>\n","      <td>d</td>\n","      <td>1</td>\n","      <td>1927</td>\n","      <td>0</td>\n","      <td>4195000</td>\n","      <td>3995000</td>\n","      <td>3900000</td>\n","      <td>148</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>202103</td>\n","      <td>Villa</td>\n","      <td>København S</td>\n","      <td>726314.7447286966</td>\n","      <td>6171972.668490626</td>\n","      <td>726396,8081</td>\n","      <td>6172178.773859339</td>\n","      <td>55,64083099</td>\n","      <td>12,5962944</td>\n","      <td>140</td>\n","      <td>136.0</td>\n","      <td>True</td>\n","      <td>a</td>\n","      <td>2</td>\n","      <td>2017</td>\n","      <td>0</td>\n","      <td>7495000</td>\n","      <td>7495000</td>\n","      <td>7595000</td>\n","      <td>17</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>201108</td>\n","      <td>Villa</td>\n","      <td>Brønshøj</td>\n","      <td>718735.9998927611</td>\n","      <td>6178448.999985718</td>\n","      <td>718818.0324674495</td>\n","      <td>6178655.165567457</td>\n","      <td>55,70238375</td>\n","      <td>12,48127579</td>\n","      <td>87</td>\n","      <td>259.0</td>\n","      <td>True</td>\n","      <td>g</td>\n","      <td>2</td>\n","      <td>1928</td>\n","      <td>0</td>\n","      <td>2250000</td>\n","      <td>2250000</td>\n","      <td>2275000</td>\n","      <td>15</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   yearMonth_sale case_type_dk zip_code_name     erts89_utm32_x  \\\n","0          201805     Rækkehus   København Ø  724656.3099617342   \n","1          201805     Rækkehus   København Ø  724612.6998841494   \n","2          202006        Villa   København S  726339.2701369224   \n","3          202103        Villa   København S  726314.7447286966   \n","4          201108        Villa      Brønshøj  718735.9998927611   \n","\n","       erts89_utm32_y             ed50_x              ed50_y    wgs84_lat  \\\n","0   6177510.129902037  724738.3771995398   6177716.274317907  55,69125957   \n","1   6177539.480294425  724694.7669242901   6177745.625006782  55,69154296   \n","2  6172005.4193364065  726421.3337691108  6172211.5248479135  55,64111328   \n","3   6171972.668490626        726396,8081   6172178.773859339  55,64083099   \n","4   6178448.999985718  718818.0324674495   6178655.165567457  55,70238375   \n","\n","     wgs84_lon  residental_area  measured_area  energy_labeled_required  \\\n","0  12,57452761              121          136.0                     True   \n","1  12,57385928              136          151.0                     True   \n","2  12,59671021              107          126.0                     True   \n","3   12,5962944              140          136.0                     True   \n","4  12,48127579               87          259.0                     True   \n","\n","  energy_labeled  amount_of_toilets  year_of_construction  renovation_year  \\\n","0              c                  2                  1882                0   \n","1              c                  2                  1882                1   \n","2              d                  1                  1927                0   \n","3              a                  2                  2017                0   \n","4              g                  2                  1928                0   \n","\n","   first_offer_price  lastest_announced_price  sold_price  \\\n","0            9895000                  9500000     8500000   \n","1            9595000                  9195000     8750000   \n","2            4195000                  3995000     3900000   \n","3            7495000                  7495000     7595000   \n","4            2250000                  2250000     2275000   \n","\n","   days_on_the_market_all_broker  change_broker  \n","0                             79              0  \n","1                             96              0  \n","2                            148              0  \n","3                             17              0  \n","4                             15              0  "]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["#Read and fast visualize the data \n","pd.set_option(\"display.max_columns\", None)\n","pd.set_option(\"display.max_rows\", None)\n","df = pd.read_csv(\"clean_housing_data.csv\")\n","print(\"Shape: \",df.shape)\n","df.head()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Prepare data for train_test_split"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["# For the moment we will not use the latitude and longitud\n","excluded_cols = [\"erts89_utm32_x\", \"erts89_utm32_y\", \"ed50_x\",\n","                 \"ed50_y\", \"wgs84_lat\", \"wgs84_lon\"]\n","\n","#Drop those columns from the data set - IN CASE WE USE THEM DELETE THIS CELL\n","df = df.drop(excluded_cols, axis=1)\n","\n","\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["We need to check if there are any categorical features that need hot encoding for some of the machine learning models. \n","One way to do this is by checking the data types of the columns:"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["This is the shape with the dummies: (57007, 37)\n"]}],"source":["\n","#Find Categorical columns & save them in a variable\n","categorical_cols = [col for col in df.columns if df[col].dtype == \"object\"]\n","\n","#Get dummies for those categorical columns\n","if categorical_cols:\n","    df = pd.get_dummies(df, columns=categorical_cols)\n","\n","#Print the new shape of DF with dummies\n","print(\"This is the shape with the dummies:\", df.shape)"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Split data"]},{"cell_type":"code","execution_count":5,"metadata":{},"outputs":[],"source":["# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(df.drop(\"sold_price\", axis=1), df[\"sold_price\"], test_size=0.2, random_state=42)\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Scaled data"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["First, The standard scaler is created in case it lead to better results"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["\n","\n","# Creating the scaler variable\n","scaler = StandardScaler()\n","#the scaler needs to be trained only in the training data and not in the test data, so it needs to be fit in there.\n","# What this will do is to adapt to all the values from the training set and create the new parameters dividing \n","# all the numbers by the Max number found in the trianig data set\n","scaler.fit(X_train)\n","\n","# Once the scaler variable has all the relative numbers, i can transform all the features so my new X_train_scaled will \n","# only have numbers potencially between 0-1. On the test data we might find numbers higher than one or just smaller since \n","# it will be divided by the higher number in the trainig set\n","X_train_standard_scaled = scaler.transform(X_train)\n","X_test_standard_scaled = scaler.transform(X_test) "]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Random Forest Regressor"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The score for the NON-scaled data is:  Train score: 0.936  ; Test score: 0.762\n","\n","The score for the SCALED data is:  Train score: 0.936  ; Test score: 0.762\n","\n"]}],"source":["# Default random forest model --> n_estimators = 10 ; max_depth = None ; max_features=”sqrt” and\n","# will state random_state=0 to reproduce the difference between nomal data and scaled data\n","\n","#I create the classifier and fit it in the NON-scaled data as the first point of comparisson\n","rfclf = RandomForestRegressor(random_state=0).fit(X_train,y_train)\n","\n","#Save the scores of the NON-scaled data \n","normal_train_score=rfclf.score(X_train,y_train)\n","normal_test_score=rfclf.score(X_test,y_test)\n","\n","print(\"The score for the NON-scaled data is:  Train score: {:.3f}  ; Test score: {:.3f}\\n\".format(normal_train_score,normal_test_score))\n","\n","\n","##I create the classifier and fit it in the SCALED data to compare with the first one. While fitting with the SCALED data, the target is not scaled\n","rfsclf = RandomForestRegressor(random_state=0).fit(X_train_standard_scaled,y_train)\n","\n","#Save the scores of the SCALED data \n","rfsclf_train_score=rfsclf.score(X_train_standard_scaled,y_train)\n","rfsclf_test_score=rfsclf.score(X_test_standard_scaled,y_test)\n","\n","print(\"The score for the SCALED data is:  Train score: {:.3f}  ; Test score: {:.3f}\\n\".format(rfsclf_train_score,rfsclf_test_score))\n","\n","\n","###################### I SHOULD PLOT THE IN A GRAPH !!!!!!!!!!!!!!!!!!!!!!!!!!!!!!!"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# MLP classifier / regressor "]},{"cell_type":"code","execution_count":9,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The score for the NON-scaled data is:  train score: 0.006 ;  test score: 0.006 \n","\n","The score for the NON-scaled data is:  train score: 0.309 ;  test score: 0.046 \n","\n"]}],"source":["# Defaul MLP model --> hidden_layers_size=100, activation function = \"relu\" ; alpha = 0.0001\n","\n","#I create the mlp with dafault parameters for the NON-scaled data\n","mlpclf = MLPClassifier(random_state=0).fit(X_train, y_train)\n","\n","#Save the scores of the NON-scaled data \n","mlp_train_score=mlpclf.score(X_train,y_train)\n","mlp_test_score=mlpclf.score(X_test,y_test)\n","\n","\n","print (\"The score for the NON-scaled data is:  train score: {:.3f} ;  test score: {:.3f} \\n\".format(mlp_train_score,mlp_test_score))\n","\n","\n","#I create the mlp with dafault parameters for the SCALED data\n","mlpsclf = MLPClassifier(random_state=0).fit(X_train_standard_scaled, y_train)\n","\n","#Save the scores of the SCALED data \n","mlps_train_score=mlpsclf.score(X_train_standard_scaled,y_train)\n","mlps_test_score=mlpsclf.score(X_test_standard_scaled,y_test)\n","\n","\n","print (\"The score for the SCALED data is:  train score: {:.3f} ;  test score: {:.3f} \\n\".format(mlps_train_score,mlps_test_score))\n"]},{"cell_type":"code","execution_count":11,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["The score for the NON-scaled data is:  train score: 0.698 ;  test score: 0.992 \n","\n","The score for the SCALED data is:  train score: -0.674 ;  test score: -0.942 \n","\n"]}],"source":["# Defaul MLP model --> hidden_layers_size=100, activation function = \"relu\" ; alpha = 0.0001\n","\n","#I create the mlp with dafault parameters for the NON-scaled data\n","mlpclf = MLPRegressor(random_state=42).fit(X_train, y_train)\n","\n","#Save the scores of the NON-scaled data \n","mlp_train_score=mlpclf.score(X_train,y_train)\n","mlp_test_score=mlpclf.score(X_test,y_test)\n","\n","\n","print (\"The score for the NON-scaled data is:  train score: {:.3f} ;  test score: {:.3f} \\n\".format(mlp_train_score,mlp_test_score))\n","\n","\n","#I create the mlp with dafault parameters for the SCALED data\n","mlpsclf = MLPRegressor(random_state=0).fit(X_train_standard_scaled, y_train)\n","\n","#Save the scores of the SCALED data \n","mlps_train_score=mlpsclf.score(X_train_standard_scaled,y_train)\n","mlps_test_score=mlpsclf.score(X_test_standard_scaled,y_test)\n","\n","\n","print (\"The score for the SCALED data is:  train score: {:.3f} ;  test score: {:.3f} \\n\".format(mlps_train_score,mlps_test_score))\n"]},{"attachments":{},"cell_type":"markdown","metadata":{},"source":["# Linear Regression\n"]},{"cell_type":"code","execution_count":18,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NON-Scaled data\n","\n","Train score: 0.639   ;   Test score: 0.991\n","\n","\n"]}],"source":["\n","Linear_reg= LinearRegression().fit(X_train, y_train)\n","\n","print(\"NON-Scaled data\\n\")\n","print(\"Train score: {:.3f}   ;   Test score: {:.3f}\\n\\n\".format(Linear_reg.score(X_train,y_train), Linear_reg.score(X_test,y_test)))\n","\n"]},{"cell_type":"code","execution_count":19,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["NON-SCALED\n","\n","Train score: 1.000   ;   Test score: -0.249\n","\n","\n"]},{"ename":"ValueError","evalue":"Number of labels=34203 does not match number of samples=45605","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[1;32m/Users/pedrofontana/Desktop/CBS/CBS 2nd Semester/Business Data Analytics, Quantitative Methods and Visualization/DBA-Project/Code_Machine_learning_process.ipynb Cell 22\u001b[0m in \u001b[0;36m<cell line: 9>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrofontana/Desktop/CBS/CBS%202nd%20Semester/Business%20Data%20Analytics%2C%20Quantitative%20Methods%20and%20Visualization/DBA-Project/Code_Machine_learning_process.ipynb#X30sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain score: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m   ;   Test score: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(dt\u001b[39m.\u001b[39mscore(X_train,y_train), dt\u001b[39m.\u001b[39mscore(X_test,y_test)))\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/pedrofontana/Desktop/CBS/CBS%202nd%20Semester/Business%20Data%20Analytics%2C%20Quantitative%20Methods%20and%20Visualization/DBA-Project/Code_Machine_learning_process.ipynb#X30sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# SCALED\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/pedrofontana/Desktop/CBS/CBS%202nd%20Semester/Business%20Data%20Analytics%2C%20Quantitative%20Methods%20and%20Visualization/DBA-Project/Code_Machine_learning_process.ipynb#X30sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m dtd \u001b[39m=\u001b[39m DecisionTreeRegressor()\u001b[39m.\u001b[39;49mfit(X_train_standard_scaled, y_train)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrofontana/Desktop/CBS/CBS%202nd%20Semester/Business%20Data%20Analytics%2C%20Quantitative%20Methods%20and%20Visualization/DBA-Project/Code_Machine_learning_process.ipynb#X30sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mSCALED:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/pedrofontana/Desktop/CBS/CBS%202nd%20Semester/Business%20Data%20Analytics%2C%20Quantitative%20Methods%20and%20Visualization/DBA-Project/Code_Machine_learning_process.ipynb#X30sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mTrain score: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m   ;   Test score: \u001b[39m\u001b[39m{:.3f}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(dtd\u001b[39m.\u001b[39mscore(X_train,y_train), dtd\u001b[39m.\u001b[39mscore(X_test,y_test)))\n","File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:1315\u001b[0m, in \u001b[0;36mDecisionTreeRegressor.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1278\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\n\u001b[1;32m   1279\u001b[0m     \u001b[39mself\u001b[39m, X, y, sample_weight\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, check_input\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, X_idx_sorted\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdeprecated\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1280\u001b[0m ):\n\u001b[1;32m   1281\u001b[0m     \u001b[39m\"\"\"Build a decision tree regressor from the training set (X, y).\u001b[39;00m\n\u001b[1;32m   1282\u001b[0m \n\u001b[1;32m   1283\u001b[0m \u001b[39m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1312\u001b[0m \u001b[39m        Fitted estimator.\u001b[39;00m\n\u001b[1;32m   1313\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1315\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m   1316\u001b[0m         X,\n\u001b[1;32m   1317\u001b[0m         y,\n\u001b[1;32m   1318\u001b[0m         sample_weight\u001b[39m=\u001b[39;49msample_weight,\n\u001b[1;32m   1319\u001b[0m         check_input\u001b[39m=\u001b[39;49mcheck_input,\n\u001b[1;32m   1320\u001b[0m         X_idx_sorted\u001b[39m=\u001b[39;49mX_idx_sorted,\n\u001b[1;32m   1321\u001b[0m     )\n\u001b[1;32m   1322\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n","File \u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/sklearn/tree/_classes.py:299\u001b[0m, in \u001b[0;36mBaseDecisionTree.fit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    296\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_features_ \u001b[39m=\u001b[39m max_features\n\u001b[1;32m    298\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(y) \u001b[39m!=\u001b[39m n_samples:\n\u001b[0;32m--> 299\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m    300\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mNumber of labels=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m does not match number of samples=\u001b[39m\u001b[39m%d\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m    301\u001b[0m         \u001b[39m%\u001b[39m (\u001b[39mlen\u001b[39m(y), n_samples)\n\u001b[1;32m    302\u001b[0m     )\n\u001b[1;32m    303\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39m0\u001b[39m \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmin_weight_fraction_leaf \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m \u001b[39m0.5\u001b[39m:\n\u001b[1;32m    304\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mmin_weight_fraction_leaf must in [0, 0.5]\u001b[39m\u001b[39m\"\u001b[39m)\n","\u001b[0;31mValueError\u001b[0m: Number of labels=34203 does not match number of samples=45605"]}],"source":["\n","# Decision Tree Regressor fitted with the first version of the data\n","dt = DecisionTreeRegressor().fit(X_train, y_train)\n","\n","print(\"NON-SCALED\\n\")\n","print(\"Train score: {:.3f}   ;   Test score: {:.3f}\\n\\n\".format(dt.score(X_train,y_train), dt.score(X_test,y_test)))\n","\n","# SCALED\n","\n","dtd = DecisionTreeRegressor().fit(X_train_standard_scaled, y_train)\n","\n","print(\"SCALED:\\n\")\n","print(\"Train score: {:.3f}   ;   Test score: {:.3f}\\n\\n\".format(dtd.score(X_train,y_train), dtd.score(X_test,y_test)))\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"deepnote_notebook_id":"d5082622-b76c-48c0-9708-7dc368e7986d","kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"},"orig_nbformat":4},"nbformat":4,"nbformat_minor":2}
